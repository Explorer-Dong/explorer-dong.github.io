---
title: 模型部分导读
status: new
---

模型主要有两个逻辑，一个是数据的传递，另一个是根据模型输出优化模型参数。前者就是模型本身的数学逻辑，后者就是一个待优化的目标函数。本文所有的模型都将会围绕这两者详细展开。

关于模型本身。从概率论的角度，传统的机器学习模型一般可以分为条件概率模型（判别式模型）和联合概率模型（生成式模型）。从字面意义上来看，这两类模型分别解决传统机器学习任务中的「预测」和「生成」任务。

关于损失函数。模型在训练/学习/拟合的过程中，必须要有一个学习准则，常见的有：经验风险最小化、结构风险最小化、最大似然估计、最大后验概率，共四种。《神经网络与深度学习》的 chapter2.3.1 [^nndl] 通过线性回归任务详细解释了这四种学习准则的理论与推导。为了便于求解，往往会将最大化准则等价转化为最小化准则。一般地，我们会将需要最小化的目标函数称作损失函数，后文这两个概念不做区分。

有了损失函数，我们就需要最小化它，常见的优化方法有：梯度下降法、牛顿法、拟牛顿等。更详细的内容见 [最优化方法 - 无约束优化方法](../../../math/optimization-method/unconstraint-optimization.md)。

[^nndl]:[邱锡鹏，神经网络与深度学习，机械工业出版社，2020.](https://nndl.github.io/)
