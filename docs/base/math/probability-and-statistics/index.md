---
title: 概率统计
---

!!! warning
    本文正在逐渐重构中。如果标题没有序号，表示该部分已经重构完成。

本文记录概率论与数理统计的学习笔记。教材参考《概率论与数理统计》 [^nnu-book]，课后答案见 [坚果云](https://www.jianguoyun.com/p/DaM9XDQQo7-eDRjLnPYFIAA)。

[^nnu-book]: 刘国祥, 王晓谦, 等. 概率论与数理统计[M]. 第一版. 北京: 科学出版社, 2013.

## 基本概念

### 随机事件与样本空间

随机事件定义为某件事情的发生情况，比起这些情况都是取决于观察的结果，没有外物干预。

样本空间定义为随机事件发生的总集合 $\Omega$。

随机事件之间的关系与运算一般可以转化为离散数学中的集合论进行分析，常见的有如下几种：

1. 包含：$A \subset B$ or $B \subset A$；
2. 相等：$A=B$；
3. 并/和：$A \cup B$；
4. 交/积：$A \cap B \quad (AB)$；
5. 互斥/互不相容：$AB=\Phi$；
6. 对立事件/余事件：$A \cap B=\Phi \land A \cup B=\Omega$；
7. 差：$A-B=A \cap \overline{B} = A \overline B$；
8. 德摩根律。

### 概率的定义及其性质

有如下三种定义方式：

1. 统计定义：认为概率 = 频率；
2. 古典定义：认为样本空间是有限集，其中每个随机事件发生的概率是等可能的。例如：分房问题、生日问题等排列组合问题；
3. 几何定义：认为样本空间是不可列的（无法表示为离散的形式），其中每个随机事件发生的概率同样是等可能的。例如：公交车乘车（一维）、蒲丰 (Buffon) 投针（二维）等几何概率问题。

### 随机事件的概率模型

**条件概率**。以 $A,B$ 两个随机事件为例，在 $A$ 发生的情况下 $B$ 发生的概率模型如下：

$$
P(B \mid A) = \frac{P(AB)}{P(A)}
$$

**联合概率**。计算方法上使用了乘法原理，其一般式如下：

$$
\begin{aligned}
P(A_1 A_2 \cdots A_n) &= P(A_1) \prod_{k=2}^n P(A_k \mid A_1 A_2 \cdots A_{k-1})\\
\text{s.t.} &\quad  (A_1A_2...A_n)>0
\end{aligned}
$$

特别地，当 $n=2$ 时，就是我们很熟悉的计算公式：

$$
\begin{aligned}
P(AB) &= P(A)\cdot P(B\mid A)\\
\text{s.t.}&\quad P(A)>0
\end{aligned}
$$

**全概模型**。我们将样本空间 $\Omega$ 完全划分为 $n$ 个互斥的区域，即 $\Omega = \sum_{i=1}^{n} A_i$ ，则在样本空间中事件 $B$ 发生的概率 $P(B)$ 就是在各子样本空间中的概率之和：

$$
\begin{aligned}
P(B) &= P(B \Omega) \\
&= P(BA_1) + P(BA_2) + \cdots + P(BA_n) \\
&= P(A_1)\cdot P(B\mid A_1) + P(A_2)\cdot P(B\mid A_2) + \cdots + P(A_n)\cdot P(B\mid A_n) \\
&= \sum_{i=1}^n P(A_i)\cdot P(B\mid A_i)
\end{aligned}
$$

**贝叶斯模型**。在上述全概模型的基础之上，现在想要求第 $j$ 个子样本空间对于事件 $B$ 的发生贡献的概率占所有子空间贡献的概率的比，那么就是一个条件概率：

$$
P(A_j\mid B) = \frac{P(A_j)\cdot P(B\mid A_j)}{\sum_{i=1}^n P(A_i)\cdot P(B\mid A_i)}
$$

可以发现全概模型是将「求解当前事件的发生概率」拆分为了「求解所有子样本空间对当前事件的发生概率之和」，而贝叶斯模型则是追溯各个子样本空间对于当前事件发生概率的贡献占比。前者是正向思维，后者是逆向思维。

### 随机事件的独立性

**独立性定义**。若 $A_1,A_2,...,A_n$ 相互独立，则有：

$$
P(A_1 A_2 \cdots A_n) = P(A_1)\cdot P(A_2)\cdots P(A_n)
$$

且 $\hat{A_1},\hat{A_2},...,\hat{A_n}$ 也相互独立，其中 $\hat{A_i} = A_i \ or \ \overline{A_i}\ (1\le i \le n)$。

注意：相互独立与两两独立不是一个意思。对于 $n$ 个事件，两两独立不考虑三个及以上的独立关系，而相互独立需要考虑 $2 \to n$ 个事件的独立关系。也就是说两两独立需要满足 $C_n^2$ 个等式关系，对于相互独立需要满足 $2^n-(n+1)$ 个等式关系，因此，两两独立 $\subset$ 相互独立。

**伯努利概型**。顺序发生 $n$ 个随机事件，随机事件之间相互独立并且只有两种可能的结果（假设为发生和不发生），利用上述的独立性定义，就有下面两个概率计算公式：

1）$n$ 个随机事件发生 $k$ 次的概率（二项概率）：

$$
C_n^k \cdot p^k \cdot (1-p)^{n-k}
$$

2）第 $n$ 个随机事件首次发生的概率（几何概率）：

$$
(1-p)^{n-1}\cdot p
$$

## 随机变量

本节我们讨论只含有一个变量的随机事件，这里的变量就可以称作随机变量，比如人类的年龄、人类的身高、抛一枚骰子的情况等。我们主要研究三个内容：

1. 随机变量的密度函数（比如人类的身高为一米八的概率）；
2. 随机变量的分布函数（比如人类身高在一米六到两米之间的概率）；
3. 随机变量函数（比如已知体重是身高的 $0.8$ 倍，我想知道人类体重的密度与分布）。

上述三点将会按「离散型」和「连续型」分别展开。

### 随机变量的定义与性质

**随机变量**。随机变量默认用大写字母 $X$ 来表示，定义域就是样本空间 $\Omega=\{ \omega \}$。

**密度函数**。一般用小写的 $p$ 来表示，例如 $p(x)$ 就表示随机变量 $X=x$ 发生的概率，等价于 $P(X=x)$。

**分布函数**。一般用大写的 $F$ 来表示，例如 $F(x)$ 就表示随机变量 $X\le x$ 发生的概率，等价于 $P(X\le x)$。形式上定义为：

$$
\forall x \in R,F(x) = \int_{-\infty}^{x} p(t)dt
$$

**一些性质**。密度函数和分布函数均有下面的性质，其实都比较显然，简单理解一下就懂了：

|   性质   | 表达式                                                       |
| :------: | :----------------------------------------------------------- |
|  非负性  | $p(x) \ge 0$                                                 |
|  正规性  | $\int_{-\infty}^{+\infty} p(x)dx = 1$                        |
|  可积性  | $\forall x_1 \le x_2,P(x_1 \le X \le x_2) = F(x_2) - F(x_1) = \int_{x_1}^{x_2}p(x)dx$ |
|  可导性  | 若 $p(x)$ 在点 $x$ 处连续，则 $F'(x) = p(x)$                 |
|  有界性  | $0 \le F(x) \le 1$，即 $\displaystyle F(-\infty) = \lim_{x \to -\infty} F(x) = 0$，$\displaystyle F(+\infty) = \lim_{x \to +\infty} F(x) = 1$ |
|  单调性  | 若 $x_1 < x_2$，则 $F(x_1) \le F(x_2)$                       |
| 右连续性 | $\displaystyle \lim_{x\to x_0^+}F(x) = F(x_0)\quad(-\infty < x_0 < +\infty)$ |

/// tc | <
随机变量的密度函数和分布函数满足的一些性质
///

注：离散型随机变量可以通过枚举随机变量 $X$ 的取值来计算概率，但连续型随机变量这么做是无意义的。因为对于连续型随机变量：

$$
\begin{aligned}
P(X=x) &= F(x) - F(x) = 0\\
P(x_1 < X < X_2)=P(x_1 < X \le X_2)&=P(x_1 \le X < X_2)=P(x_1 \le X \le X_2)\\
\text{s.t.}\quad &\forall x \in R
\end{aligned}
$$

因此在连续型随机变量的情况下，$P(A) = 0$ 不能推出 $A$ 是不可能事件，同理 $P(A)=1$ 也不能推出 $A$ 是必然事件。事实上，连续型随机变量中，利用分布函数计算密度函数取值是借助了微分的思想：

$$
p(x)\Delta x \approx \int_{x}^{x+\Delta x} p(t)dt = F(x+\Delta x) - F(x) = P(x \le X \le x+\Delta x)
$$

### 离散型随机变量的密度函数和分布函数

!!! tip
    其实离散型随机变量的密度函数应该叫做「分布列」的，但是本质就是密度函数，我们统一成一个说法。

离散型随机变量的取值是可列的，有以下三种表示方法：

|  名称  |                            表达式                            |
| :----: | :----------------------------------------------------------: |
| 公式法 |            $p_k = P(X=x_k),\quad k = 1,2,\cdots$             |
| 服从法 | $X \sim \begin{pmatrix}x_1 & x_2 & x_3 & \cdots \\ p_1 & p_2 & p_3 & \cdots \end{pmatrix}$ |
| 表格法 | $\begin{array}{c:cccc} X & x_1 & x_2 & x_3 & \cdots \\ \hline P & p_1 & p_2 & p_3 & \cdots \end{array}$ |

/// tc | <
离散型随机变量的表示方法
///

知道了离散型随机变量的表示方法后，我们介绍几个常用的离散型随机变量及其密度函数，分布函数累加就行了，这里不展开。

**0-1 分布（两点分布）**：随机变量只有两种可能的取值。

- 密度函数：$P(X=0)=1-p,P(X=1)=p$，其中 $0\le p\le 1$；
- 记作：$X \sim \begin{pmatrix} 0 & 1 \\ 1-p & p \end{pmatrix}$。

**二项分布（n 重伯努利试验）**：$P(X=k)$ 表示 $n$ 次相互独立的 0-1 分布事件中，有 $k$ 次事件发生的概率。

- 密度函数：$P(X=k) = C_n^k \cdot p^k \cdot (1-p)^{n-k}$，其中 $k\in \{0,1,\cdots,n\}$；
- 记作：$X \sim B(n,p)$。

**泊松分布**：当二项分布的 $n$ 趋近于无穷时，就近似成了泊松分布。

- 密度函数：$\displaystyle P(X=k)=C_n^k \cdot p^k \cdot (1-p)^{n-k} \to \frac{\lambda^k}{k!}\cdot e^{-\lambda}$，其中常数 $\lambda > 0$；
- 记作：$X \sim P(\lambda)$。

??? note "泊松分布正规性证明"

    $$
    \begin{aligned}
    \sum_{k=0}^{\infty} P(X=k)
    &= \sum_{k=0}^{\infty}\frac{\lambda^k}{k!}\cdot e^{-\lambda} \\
    &= e^{-\lambda} \cdot \left( \frac{\lambda^0}{0!} + \frac{\lambda^1}{1!} + \frac{\lambda^2}{2!} + \cdots \right) \\
    &= e^{-\lambda} \cdot e^\lambda \\
    &= 1
    \end{aligned}
    $$
    
    证毕。其中倒数第三行用到了 $e^x$ 的泰勒展开公式：
    
    $$
    e^x = 1+x+\frac{x^2}{2!}+\cdots
    $$

**几何分布**：$P(X=k)$ 表示 $n$ 次相互独立的 0-1 分布事件中，第 $k$ 次事件首次发生的概率。

- 密度函数：$P(X=k)=(1-p)^{k-1}p$，其中 $k\in \{0,1,\cdots,n\}$；
- 记作：$X \sim G(p)$。

**超几何分布**：$P(X=k)$ 表示在 $N$ 件含有 $M$ 个次品的样品总体中无放回的抽取 $n$ 件，其中含有 $k$ 件次品的概率。

- 密度函数：$\displaystyle P(X=k)=\frac{C_M^k C_{N-M}^{n-k}}{C_N^n}$，其中 $k\in \{0,1,2,\cdots,\min{(n, M)}\}$；
- 记作：$X \sim \text{超几何分布}(n,N,M)$。

### 连续型随机变量的密度函数和分布函数

介绍几个常用的连续型随机变量及其密度函数和分布函数：

|   名称   |           记法           |                        密度函数表达式                        |                        分布函数表达式                        |
| :------: | :----------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 均匀分布 |     $X \sim U[a,b]$      | $p(x) = \begin{cases} \frac{1}{b-a}, & a \le x \le b, \\ 0, & \text{其他} \end{cases}$ | $F(x) = \begin{cases} 0, & x < a \\ \frac{x - a}{b - a}, & a \le x < b \\ 1, & x \ge b \end{cases}$ |
| 指数分布 |   $X \sim e (\lambda)$   | $p(x) = \begin{cases} 0, & x < 0 \\ \lambda e^{-\lambda x} , & x \ge 0 \end{cases},\quad\lambda >0$ | $F(x) = \begin{cases} 0, & x < 0 \\ 1- e^{-\lambda x}, & x \ge 0 \end{cases}$ |
| 正态分布 | $X \sim N(\mu,\sigma^2)$ | $p(x) = \frac{1}{\sqrt{2 \pi} \sigma } e^{- \frac{(x - \mu)^2}{2 \sigma ^2}} , \quad -\infty < x < + \infty$ | $F(x) = \frac{1}{\sqrt{2 \pi} \sigma } \int_{- \infty}^x e^{- \frac{(y - \mu)^2}{2 \sigma ^2}} dy$ |

/// tc
连续型随机变量及其密度函数和分布函数
///

注：为了手算方便，在计算一般正态分布函数 $F(x)$ 的具体函数值时，可以先将其转化为标准正态分布函数 $\Phi(x)$，然后直接查表就可以得到具体函数值，转换公式如下：

$$
P(X \le x) = F(x) = \Phi (\frac{x - \mu}{\sigma})
$$

### 随机变量函数

所谓随机变量函数，就是将一个随机变量 $X$ 通过某种映射关系 $g(\cdot)$ 转换为一个新的随机变量 $Y$，即 $y=g(x)$，然后通过 $p_X(x)$ 求出 $p_Y(y)$ 和 $F_Y(y)$ 的一个过程。应用场景也挺常见的，比如已知身高和体重存在某种关系，然后还知道身高的密度函数，就可以直接算出来体重的密度函数和分布函数了。

**对于离散型随机变量**。直接根据映射关系 $g(\cdot)$ 枚举 $X$ 就可以得到 $Y$ 的密度函数和分布函数了，没什么学问在里面。

**对于连续型随机变量**。有两种方法：

1）先求 $Y$ 的分布函数 $F_Y(y)$，再通过对其求导得到密度函数 $p_Y(y)$。具体地：

$$
\begin{aligned}
F_Y(y) &= P(Y \le y) \\&= P(g(X) \le y) \\&= P(X \le f(y)) \\&= F_X(f(y)) &(1)\\
p_Y(y) &= \frac{d}{dy} F_Y(y) \\&= \frac{d}{dy} F_X(f(y)) \\&= F_X'(f(y)) \cdot f'(y) \\&= p_X(f(y)) \cdot f'(y) &(2)
\end{aligned}
$$

2）如果关系式 $y=g(x)$ 单调且反函数 $x=h(y)$ 连续可导，则可以直接得出随机变量 $Y$ 的密度函数 $p_Y(y)$：

$$
p_Y(y) =
\begin{cases}
p_X(h(y)) \cdot |h'(y)|, & \alpha < y < \beta \\
0, & \text{其他}
\end{cases}
$$

公式不予证明。其中 $\alpha$ 和 $\beta$ 为 $Y=g(X)$ 的取值范围（$x$ 应该怎么取值，$h(y)$ 就应该怎么取值，从而计算出 $y$ 的取值范围）。

## 3 随机向量

实际生活中，只采用一个随机变量描述事件往往是不够的。本章引入多维的随机变量概念，构成随机向量，从二维开始，推广到 $n$ 维。

### 3.1 二维随机向量的联合分布

现在我们讨论二维随机向量的联合分布。所谓的联合分布，其实就是一个曲面的概率密度（离散型就是点集），而分布函数就是对其积分得到的三维几何体的体积（散点和）而已。

#### 3.1.1 联合分布函数

定义：我们定义满足下式的二元函数 $F(x,y)$ 为二维随机向量 $(X,Y)$ 的联合分布函数

$$
F(x,y) = P((X \le x) \cap (Y \le y)) = P(X \le x, Y \le y)
$$

??? note "几何意义：F(x,y) 即左下方无界矩形的面积"

    ![联合分布函数的几何意义](https://cdn.dwj601.cn/images/202403271717479.png)

性质：其实配合几何意义理解就会很容易了

1. 固定某一维度，另一维度是单调不减的
2. 对于每个维度都是右连续的
3. 固定某一维度，另一维度趋近于负无穷对应的函数值为 $0$
4. 二维前缀和性质，右上角的矩阵面积 $\ge 0$

#### 3.1.2 联合分布列

定义：若二维随机向量 $(X,Y)$ 的所有可能取值是至多可列的，则称 $(X,Y)$ 为二维离散型随机向量

表示：有两种表示二维随机向量分布列的方法，如下

??? note "二维随机向量分布列的表示方法"
    1. 公式法

        $$
        p_{ij} = P(X=x_i,Y = y_i), \quad i,j=1,2,\cdots
        $$
    
    2. 表格法：
        ![二维联合分布列](https://cdn.dwj601.cn/images/202403271728248.png)

性质：

1. 非负性：$p_{ij} \ge 0, \quad i,j=1,2,\cdots$
2. 正规性：$\displaystyle \sum_{i} \sum_{j} p_{ij} = 1$

#### 3.1.3 联合密度函数

定义：

$$
F(x,y) = \int_{-\infty}^x \int_{-\infty}^y p(u,v)dudv
$$

性质：

1. 非负性：$\forall x,y \in R,p(x,y) \ge 0$
2. 正规性：$\displaystyle \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} p(x,y)dxdy = 1$

结论：

1. **联合分布函数**相比于一元分布函数，其实就是从概率密度函数与 $x$ 轴围成的面积转变为了概率密度曲面与 $xOy$ 平面围成的**体积**
2. 若概率密度曲面在 $xOy$ 平面的投影为点集或线集，则对应的概率显然为零

常见的连续型二维分布：

1. 二维均匀分布：假设该曲面与 $xOy$ 面的投影面积为 $S$，则分布函数其实就是一个高为定值 $\frac{1}{S}$ 的柱体，密度函数为：

    $$
    p(x,y) =
    \begin{cases}
    \frac{1}{S}, &(x,y) \in G \\
    0, &\text{其他}
    \end{cases}
    $$

2. 二元正态分布：不要求掌握密度函数，可以感受一下密度函数的图像：

    ??? note "二元正态分布 - 密度函数的图像"

        ![二元正态分布 - 密度函数的图像](https://cdn.dwj601.cn/images/202403290948792.png)

计算题：往往给出一个二元密度函数，然后让我们求解（1）密度函数中的参数、（2）分布函数、（3）联合事件某个区域下的概率

（1）我们利用二元密度函数的正规性，直接积分值为 $1$ 即可

（2）划分区间后进行曲面积分即可，在曲面积分时往往结合 $X$ 型和 $Y$ 型的二重积分进行

（3）画出概率密度曲面在 $xOy$ 面的投影，然后积分即可

### 3.2 二维随机向量的边缘分布

对于二元分布函数，我们也可以研究其中任意一个随机变量的分布情况，而不需要考虑另一个随机变量的取值情况。举一个实例就是，假如当前的随机向量是身高和体重，所谓的只研究其中一个随机变量，即边缘分布函数的情形就是，我们不考虑身高只考虑体重的分布情况；或者我们不考虑体重，只考虑身高的分布情况。接下来，我们将从边缘分布函数入手，逐渐学习离散型的分布列与连续型的分布函数。

#### 3.2.1 边缘分布函数

我们称 $F_X(x),F_Y(y$) 分别为 $(X,Y)$ 关于 $X,Y$ 的边缘分布函数，定义式为：

$$
\begin{aligned}
F_X(x) = P(X \le x) = P(X \le x,Y < +\infty) = \lim_{y \to +\infty} F(x,y) = F(x,+\infty) \\
F_Y(y) = P(Y \le y) = P(X < +\infty, Y \le y) = \lim_{x \to +\infty} F(x,y) = F(+\infty,y)
\end{aligned}
$$

#### 3.2.2 边缘分布列

所谓的边缘分布列，就是固定一个随机变量，另外的随机变量取遍，组成的分布列。即：

$$
\begin{aligned}
P(X=x_i) = p_{i\cdot}=\sum_{j=1}^{+\infty} p_{ij}, \quad i=1,2,\cdots \\
P(Y=y_j) = p_{\cdot j}=\sum_{i=1}^{+\infty} p_{ij}, \quad j=1,2,\cdots
\end{aligned}
$$

我们称：

- $P(X=x_i)$ 为随机向量 $(X,Y)$ 关于 $X$ 的边缘分布列

- $P(Y=y_j)$ 为随机向量 $(X,Y)$ 关于 $Y$ 的边缘分布列

#### 3.2.3 边缘密度函数

所谓的的边缘密度函数，可以与边缘分布列进行类比，也就是固定一个随机变量，另外的随机变量取遍。只不过连续型的取遍就是无数个点，而离散型的取遍是可列个点，仅此而已。即：

$$
\begin{aligned}
P(X=x) &= p_X(x) \\
&= \frac{d}{dx} F_X(x) \\
&= \frac{d}{dx} F(x,+\infty) \\
&= \frac{d}{dx} \int_{-\infty}^{x} \left [ \int_{-\infty}^{+\infty} p(u,v) dv \right ] du \\
&= \int_{-\infty}^{+\infty} p(x,y) dy \\
\end{aligned}
$$

$$
\begin{aligned}
P(Y=y) &= p_Y(y) \\
&= \frac{d}{dy} F_Y(y) \\
&= \frac{d}{dy} F(+\infty,y) \\
&= \frac{d}{dy} \int_{-\infty}^{+\infty} \left [ \int_{-\infty}^{y} p(u,v) dv \right ] du \\
&= \frac{d}{dy} \int_{-\infty}^{y} \left [ \int_{-\infty}^{+\infty} p(u,v) du \right ] dv \\
&= \int_{-\infty}^{+\infty} p(x,y) dx \\
\end{aligned}
$$

我们称：

- $P(X=x)$ 为随机向量 $(X,Y)$ 关于 $X$ 的边缘密度函数

- $P(Y=y)$ 为随机向量 $(X,Y)$ 关于 $Y$ 的边缘密度函数

### 3.3 随机向量的条件分布

本目主要介绍的是条件分布。所谓的条件分布，其实就是在约束一个随机变量为定值的情况下，另外一个随机变量的取值情况。与上述联合分布、边缘分布的区别在于：

- 联合分布、边缘分布的分布函数是一个体积（散点和），概率密度（分布列）是一个曲面（点集）
- 条件分布的分布函数是一个面积（散点和），概率密度（分布列）是一个曲线（点集）

#### 3.3.1 离散型随机向量的条件分布列和条件分布函数

条件分布列，即散点情况：

$$
\begin{aligned}
p_{i|j} = P(X=x_i\ |\ Y=y_j) = \frac{P(X=x_i,Y=y_i)}{P(Y=y_i)} = \frac{p_{ij}}{p_{\cdot j}}, \quad i=1,2,\cdots \\
p_{j|i} = P(Y=y_j\ |\ X=x_i) = \frac{P(X=x_i,Y=y_i)}{P(X=x_i)} = \frac{p_{ij}}{p_{i\cdot }}, \quad j=1,2,\cdots
\end{aligned}
$$

我们称：

- $p_{i|j}$ 为在给定 $Y=y_j$ 的条件下 $X$ 的条件分布列

- $p_{j|i}$ 为在给定 $X=x_i$ 的条件下 $Y$ 的条件分布列

条件分布函数，即点集情况：

$$
\begin{aligned}
F(x|y_j) = P(X \le x\ | \ Y=y_j) = \sum _{x_i\le x} \frac{p_{ij}}{p_{\cdot j}} \\
F(y|x_i) = P(Y \le y\ | \ X=x_i) = \sum _{y_j\le y} \frac{p_{ij}}{p_{i \cdot}}
\end{aligned}
$$

我们称：

- $F(x|y_j)$ 为在给定 $Y=y_j$ 的条件下 $X$ 的条件分布函数
- $F(y|x_i)$ 为在给定 $X=x_i$ 的条件下 $Y$ 的条件分布函数

#### 3.3.2 连续型随机向量的条件密度函数和条件分布函数

条件密度函数，即联合分布的概率密度曲面上，约束了某一维度的随机变量为定值，于是条件密度函数的图像就是一个空间曲线：

$$
\begin{aligned}
p(x|y) = \frac{p(x,y)}{p_Y(y)}, \quad -\infty < x < +\infty \\
p(y|x) = \frac{p(x,y)}{p_X(x)}, \quad -\infty < y < +\infty
\end{aligned}
$$

我们称：

- $p(x|y)$ 为在给定 $Y=y$ 的条件下 $X$ 的条件密度函数
- $p(y|x)$ 为在给定 $X=x$ 的条件下 $Y$ 的条件密度函数

条件分布函数，即上述曲线的分段积分结果：

$$
\begin{aligned}
F(x|y) = P(X \le x \ | \ Y=y) = \int_{-\infty}^x \frac{p(u,y)}{p_Y(y)} du,\quad -\infty < x < +\infty \\
F(y|x) = P(Y \le y \ | \ X=x) = \int_{-\infty}^y \frac{p(x,v)}{p_X(x)} dv, \quad -\infty < y < +\infty
\end{aligned}
$$

我们称：

- $F(x|y)$ 为在给定 $Y=y$ 的条件下 $X$ 的条件分布函数
- $F(y|x)$ 为在给定 $X=x$ 的条件下 $Y$ 的条件分布函数

### 3.4 随机变量的独立性

本目主要介绍随机变量的独立性。我们知道随机事件之间是有独立性的，即满足 $P(AB)=P(A)P(B)$ 的事件，那么随机变量之间也有独立性吗？答案是有的，以生活中的例子为实例，比如我和某个同学进教室，就是独立的两个随机变量。

定义。我们定义如果两个随机变量的分布函数满足下式，则两个随机变量相互独立：

$$
F(x,y)=F_X(x)F_Y(y)
$$

性质。对于随机向量 $(X,Y)$：

1. 随机变量 $X$ 和 $Y$ 相互独立的充分必要条件是：
    - 离散型：$P(X=x_i,Y=y_j) = P(X=x_i)P(Y=y_j)$
    - 连续型：$p(x,y) = p_X(x)p_Y(y)$
2. 若随机变量 $X$ 和 $Y$ 相互独立，且 $h(\cdot)$ 和 $g(\cdot)$ 连续，则 $h(X),g(Y)$ 也相互独立。

### 3.5 随机向量函数的分布

在 2.4 目中我们了解到了随机变量函数的分布，现在我们讨论随机向量函数的分布。在生活中，假设我们已经知道了一个人群中所有人的身高和体重的分布情况，现在想要血糖根据身高和体重的分布情况，就需要用到本目的理念。我们从离散型和连续型随机向量 $(X,Y)$ 出发，讨论 $g(X,Y)$ 的分布情况。

#### 3.5.1 离散型随机向量函数的分布

按照规则枚举即可。

#### 3.5.2 连续型随机向量函数的分布

与连续型随机变量函数的分布类似，这类题目一般也是：给定随机向量 $(X,Y)$ 的密度函数 $p(x,y)$ 和 映射函数 $g(x,y)$，现在需要求解 $Z=g(X,Y)$ 的分布函数（若 $g(x,y)$ 二元连续，则 $Z$ 也是连续型随机变量）。方法同理，先求解 $Z$ 的分布函数，再对 $z$ 求导得到密度函数 $p_Z(z)$。接下来我们介绍两种常见随机向量的分布。

**(1) 和的分布：**

- 先求分布函数 $F_Z(z)$：
  
    $$
    \begin{aligned}
    F_Z(z) &= P(X+Y \le z) \\
    &= \iint\limits_{x+y \le z} p(x,y) dxdy \\
    &= \int _{-\infty}^z \left [ \int_{-\infty}^{+\infty} p(x,t-x)dx \right ] dt \quad (1) \\
    &= \int _{-\infty}^z \left [ \int_{-\infty}^{+\infty} p(t-y,y)dy \right ] dt \quad (2)
    \end{aligned}
    $$

- 由分布函数定义：
  
    $$
    F_X(x) = \int_{-\infty}^xp(u)du
    $$

- 所以可得 $Z=X+Y$ 的密度函数 $p_Z(z)$ 为：
  
    $$
    \begin{aligned}
    p_Z(z) = \int_{-\infty}^{+\infty} p(x,z-x)dx \quad &(1) \\
    p_Z(z) = \int_{-\infty}^{+\infty} p(z-y,y)dy \quad &(2) \\
    \end{aligned}
    $$

- 若 X 和 Y 相互独立，还可得卷积式：
  
    $$
    \begin{aligned}
    p_Z(z) &= \int_{-\infty}^{+\infty} p(x,z-x)dx \\
    &= \int_{-\infty}^{+\infty} p_X(x)\cdot p_Y(z-x) dx \quad &(1) \\
    p_Z(z) &= \int_{-\infty}^{+\infty} p(z-y,y)dy \\
    &= \int_{-\infty}^{+\infty} p_X(z-y)\cdot p_Y(y) dy \quad &(2)
    \end{aligned}
    $$

**(2) 次序统计量的分布（对于两个相互独立的随机变量 X 和 Y）：**

- 对于 $M=\max{(X,Y)}$ 的分布函数，有：

    $$
    \begin{aligned}
    F_M(z) &= P(M \le z) \\
    &= P(\max{(X,Y)} \le z) \\
    &= P(X \le z, Y \le z) \\
    &= P(X \le z) \cdot P(Y \le z) \\
    &= F_X(z) \cdot F_Y(z)
    \end{aligned}
    $$

- 对于 $N=\min{(X,Y)}$ 的分布函数，有：

    $$
    \begin{aligned}
    F_N(z) &= P(N \le z) \\
    &= P(\min{(X,Y)} \le z) \\
    &= 1 - P(\min{(X+Y)} \ge z) \\
    &= 1 - P(X \ge z,Y \ge z) \\
    &= 1 - P(X \ge z) \cdot P(Y \ge z) \\
    &= 1 - [1 - F_X(z)] \cdot [1 - F_Y(z)]
    \end{aligned}
    $$

- 若拓展到 $n$ 个相互独立且同分布的随机变量，则有：

    $$
    \begin{aligned}
    F_M(z) &= [F(z)]^n \\
    p_M(z) &= np(z)[F(z)]^{n-1}
    \end{aligned}
    $$

    $$
    \begin{aligned}
    F_N(z) &= 1 - [1-F(z)]^n \\
    p_N(z) &= np(z)[1-F(z)]^{n-1}
    \end{aligned}
    $$

## 4 随机变量的数字特征

本章我们将学习随机变量的一些数字特征。所谓的数字特征其实就是随机变量分布的一些内在属性，比如均值、方差、协方差等等，有些分布特性甚至可以通过某个数字特征而直接觉得。其中**期望**和**方差**往往用来衡量单个随机变量的特征，而**协方差**与**相关系数**则是用来衡量随机变量之间的数字特征。接下来开始介绍。

### 4.1 数学期望

**加权平均**概念的严格数学定义。

#### 4.1.1 随机变量的数学期望

- 离散型

    $$
    EX = \sum_{i=1}^{\infty} x_i p_i
    $$

- 连续型

    $$
    \begin{aligned}
    &EX = \int_{-\infty}^{+\infty} xp(x)dx
    \end{aligned}
    $$

#### 4.1.2 随机变量函数的数学期望

- 离散型

    - 一元

        $$
        Eg(X) = \sum_{i=1}^{\infty}g(x_i)p_i
        $$

    - 二元

        $$
        Eg(X,Y) = \sum_{i=1}^{\infty}\sum_{j=1}^{\infty}g(x_i,y_i)p_{ij}
        $$

- 连续型

    - 一元

        $$
        Eg(X) = \int_{-\infty}^{+\infty}g(x)p(x)dx
        $$

    - 二元

        $$
        Eg(X,Y) = \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}g(x_i,y_i)p(x,y)dxdy
        $$

#### 4.1.3 数学期望的性质

1. $EC=C$
2. $E(CX)=CEX$
3. $E(X+Y)=EX+EY$
4. 若 $X$ 和 $Y$ 相互独立，则 $E(XY)=EXEY$

### 4.2 方差

随机变量的取值与均值之间的**离散程度**。

#### 4.2.1 方差的定义

我们定义随机变量 $X$ 的方差 $D(X)$ 为：（全部可由期望的性质推导而来）

$$
\begin{aligned}
D(X) &= E\left[(X-EX)^2\right ] \\
&= E\left ( X^2 \right ) - (EX)^2
\end{aligned}
$$

#### 4.2.2 方差的性质

下列方差的性质全部可由上述方差的定义式，结合期望的性质推导而来：

1. $D(aX+b) = a^2D(X)$

2. 若 $X_1,X_2,\cdots$ 相互独立，则 $D(aX_1 \pm bX_2 \pm \cdots) = a^2D(X_1) + b^2D(X_2) + \cdots$

3. $E\left[ (X-EX)^2 \right] \le E \left [ (X-C)^2 \right ]$

4. 切比雪夫不等式：

    $$
    \forall \epsilon >0, P(|X - EX| < \epsilon) \ge 1 - \frac{DX}{\epsilon^2}
    $$

### 4.3 结论与推导（补）

|  类型  |   分布    |                          符号                           |            期望 $E(X)$            |             方差 $D(X)$             |
| :----: | :-------: | :-----------------------------------------------------: | :-------------------------------: | :---------------------------------: |
| 离散型 | 0-1 分布  | $X \sim \begin{pmatrix} 0 & 1 \\ 1-p & p \end{pmatrix}$ |                $p$                |              $p(1-p)$               |
|  ---   | *二项分布 |                     $X \sim B(n,p)$                     |               $np$                |              $np(1-p)$              |
|  ---   | 几何分布  |                      $X \sim G(p)$                      |    $\displaystyle \frac{1}{p}$    |   $\displaystyle \frac{1-p}{p^2}$   |
|  ---   | *泊松分布 |                   $X \sim P(\lambda)$                   |             $\lambda$             |              $\lambda$              |
| 连续型 | 均匀分布  |                     $X \sim U[a,b]$                     |   $\displaystyle \frac{a+b}{2}$   | $\displaystyle \frac{(b-a)^2}{12}$  |
|  ---   | 指数分布  |                   $X \sim e(\lambda)$                   | $\displaystyle \frac{1}{\lambda}$ | $\displaystyle \frac{1}{\lambda^2}$ |
|  ---   | *正态分布 |                $X \sim N(\mu,\sigma^2)$                 |               $\mu$               |             $\sigma^2$              |

注：打星号表示在两个随机变量 $X,Y$ 相互独立时，具备可加性。具体的：

$$
\begin{aligned}
X \sim N(\mu_1,\sigma_1^2), Y \sim N(\mu_2,\sigma_2^2) &\to X\pm Y\sim N(\mu_1\pm\mu_2,\sigma_1^2+\sigma_2^2)\\
X \sim B(n_1,p), Y \sim B(n_2,p) &\to X+Y\sim B(n_1+n_2,p)\\
X \sim P(\lambda_1),Y\sim P(\lambda_2) &\to X+Y \sim P(\lambda_1+\lambda_2)
\end{aligned}
$$

???+note "公式推导"
    推导的根本方式还是从定义出发。当然为了省事也可以从性质出发。
    === "0-1 分布"
        ![0-1 分布](https://cdn.dwj601.cn/images/202404202313030.jpg)
    === "二项分布"
        ![二项分布](https://cdn.dwj601.cn/images/202404202313503.jpg)
    === "几何分布"
        ![几何分布](https://cdn.dwj601.cn/images/202404202313329.jpg)
    === "泊松分布"
        ![泊松分布](https://cdn.dwj601.cn/images/202404202313316.jpg)
    === "均匀分布"
        ![均匀分布](https://cdn.dwj601.cn/images/202404202313239.jpg)
    === "指数分布"
        ![指数分布](https://cdn.dwj601.cn/images/202404202313832.jpg)

### 4.4 协方差与相关系数

#### 4.4.1 协方差

定义：随机变量 X 与 Y 的协方差 $Cov(X,Y)$ 为：

$$
\begin{aligned}
Cov(X,Y)&= E[(X-EX)(Y-EY)] \\
&= E(XY) - EXEY
\end{aligned}
$$

特别的：

$$
Cov(X,X) = DX
$$

性质：

1. 交换律：$Cov(X,Y)=Cov(Y,X)$
2. 提取率：$Cov(aX,bY)=abCov(X,Y)$
3. 分配率：$Cov(X_1+X_2,Y) = Cov(X_1,Y)+Cov(X_2,Y)$
4. 独立性：若 X 与 Y 相互独立，则 $Cov(X,Y)=0$；反之不一定成立
5. 放缩性：$\left[Cov(X,Y)\right]^2 \le DX \cdot DY$

#### 4.4.2 相关系数

定义：相关系数 $\rho$ 是用来刻画两个随机变量之间**线性**相关关系强弱的一个数字特征，注意是线性关系。$|\rho|$ 越接近 0，则说明两个随机变量越不线性相关；$|\rho|$ 越接近 1，则说明两个随机变量越线性相关，定义式为

$$
\rho_{X,Y} = \frac{Cov(X,Y)}{\sqrt{DX}\sqrt{DY}}
$$

特别的：

1. 若 $0 < \rho < 1$，则称 X 与 Y 正相关
2. 若 $-1<\rho<0$，则称 X 与 Y 负相关

性质：

1. 放缩性（由协方差性质5可得）：$|\rho| \le 1$
2. 独立性（由协方差性质4可得）：若 X 与 Y 相互独立，则 $p=0$；反之不一定成立
3. 线性相关性（不予证明）：$|\rho|=1$ 的充分必要条件是存在常数 $a(a\ne0),b$ 使得 $P(Y=aX+b)=1$

#### 4.4.3 独立性与线性相关性（补）

一般的：对于两个随机变量 $X$ 和 $Y$

- $X$ 和 $Y$ 相互独立 $\rightarrow$ $X$ 和 $Y$ 线性无关（可以用线性相关的定义式结合协方差计算公式导出）
- $X$ 和 $Y$ 相互独立 $\nleftarrow$ $X$ 和 $Y$ 线性无关（因为有可能出现 $X$ 和 $Y$ 非线性相关）

特别的：对于满足二维正态分布的随机变量 $X$ 和 $Y$，即 $(X,Y) \sim (\mu_1,\mu_2,\sigma_1^2,\sigma_2^2,\rho)$

- $X$ 和 $Y$ 相互独立 $\rightarrow$ $X$ 和 $Y$ 线性无关
- $X$ 和 $Y$ 相互独立 $\leftarrow$ $X$ 和 $Y$ 线性无关

???+note "证明 - 二维正态分布的两个随机变量：相互独立 $\iff$ 线性无关"
    ![二维正态分布的两个随机变量：相互独立 等价于 线性无关](https://cdn.dwj601.cn/images/202404261112302.jpg)
    参考：<https://www.zhihu.com/question/29641138>

## 5 大数定律与中心极限定理

本章只需要知道一个**独立同分布中心极限定理**即可，至于**棣莫弗-拉普拉斯中心极限定理**其实就是前者的 $\{X_i\}_{i=1}^{\infty}$ 服从伯努利 $n$ 重分布罢了。

### 独立同分布中心极限定理

定义：$\{X_i\}_{i=1}^{\infty}$ 独立同分布且非零方差，其中 $EX_i=\mu,DX_i=\sigma^2$，则有：

$$
\begin{aligned}
\sum_{i=1}^n X_i &\sim N(\sum_{i=1}^n(EX_i),\sum_{i=1}^n(DX_i)) \\
&\sim N(n\mu,n\sigma^2)
\end{aligned}
$$

解释：其实就是对于独立同分布的随机事件 $X_i$，在事件数 $n$ 足够大时，就近似为正态分布（术语叫做**依分布**）。这样就可以很方便利用正态分布的性质计算当前事件的概率。至于**棣莫弗-拉普拉斯中心极限定理**就是上述 $\mu=p,\sigma^2=p(1-p)$ 的特殊情况罢了

## 6 数理统计的基本概念

开始统计学之旅。

### 6.1 总体与样本

~~类比 ML：数据集=总体，样本=样本。~~

我们只研究一种样本：简单随机样本 $(X_1,X_2,...,X_n)$。符合下列两种特点：

1. $(X_1,X_2,...,X_n)$ 相互独立
2. $(X_1,X_2,...,X_n)$ 同分布

同样的，我们研究总体 $X$ 的分布与概率密度，一般概率密度会直接给，需要我们在此基础之上研究所有样本的联合密度：

- 分布：由于样本相互独立，故：

    $$
    F(x_1,x_2,...,x_n)=F(x_1)F(x_2) \cdots F(x_n)
    $$

- 联合密度：同样由于样本相互独立，故：

    $$
    p(x_1,x_2,...,x_n)=p(x_1)p(x_2) \cdots p(x_n)
    $$

### 6.2 经验分布与频率直方图

经验分布函数是利用样本得到的。也是给区间然后统计样本频度进而计算频率，只不过区间长度不是固定的。

频率直方图就是选定**固定**的区间长度，然后统计频度进而计算频率作图。

### 6.3 统计量

**统计量定义**：关于样本不含未知数的表达式。

**常见统计量**：假设 $(X_1,X_2,...,X_n)$ 为来自总体 $X$ 的简单随机样本

一、样本均值和样本方差

- 样本均值：$\displaystyle \overline{X} = \frac{1}{n} \sum_{i=1}^n X_i$
- 样本方差：$\displaystyle S_0^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2 = \frac{1}{n}\sum_{i=1}^n X_i^2 - \overline{X}^2$
- 样本标准差：$\displaystyle S_0 = \sqrt{S_0^2}$
- 修正样本方差：$\displaystyle S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2$
- 修正样本标准差：$\displaystyle S = \sqrt{S^2}$
  ??? note "推导"

    设总体 $X$ 的数学期望和方差分别为 $\mu$ 和 $\sigma^2$，$(X_1,X_2,...,X_n)$ 是简单随机样本，则：

    ![样本均值的数学期望与总体的数学期望相等](https://cdn.dwj601.cn/images/202405101145088.png)

    即：样本均值的数学期望 $=$ 总体的数学期望

    ![样本方差的数学期望与总体的数学期望 不相等](https://cdn.dwj601.cn/images/202405101148690.png)

    即：样本方差的数学期望 $\ne$ 总体的数学期望

    ![修正样本方差推导](https://cdn.dwj601.cn/images/202405101148126.png)

    上图即：修正样本方差推导
  
- 样本 $k$ 阶原点矩：$\displaystyle A_k = \frac{1}{n} \sum_{i=1}^n X_i^k,\quad k=1,2,\cdots$

- 样本 $k$ 阶中心矩：$\displaystyle B_k = \frac{1}{n} \sum_{i=1}^n (X_i-\overline{X})^k,\quad k=2,3,\cdots$

二、次序统计量

- 序列最小值
- 序列最大值
- 极差 = 序列最大值 - 序列最小值

### 6.4 正态总体抽样分布定理

时刻牢记一句话：构造性定义！

#### 6.4.1 卡方分布、t 分布、F 分布

分位数：

- 我们定义实数 $\lambda_\alpha$ 为随机变量 $X$ 的上侧 $\alpha$ 分位数（点）当且仅当 $P(X > \lambda_\alpha) = \alpha$
- 我们定义实数 $\lambda_{1-\beta}$ 为随机变量 $X$ 的下侧 $\beta$ 分位数（点）当且仅当 $P(X < \lambda_{1-\beta})=\beta$

$\chi^2$ 分布：

密度函数图像：

![密度函数图像](https://cdn.dwj601.cn/images/202405171013305.webp)

定义：

- 对于 $n$ 个独立同分布的标准正态随机变量 $X_1,X_2,\cdots ,X_n$，若 $Y = X_1^2 + X_2^2 + \cdots + X_n^2$
- 则 $Y$ 服从自由度为 $n$ 的 $\chi^2$ 分布，记作：$Y \sim \chi^2(n)$

性质：

- 可加性：若 $Y_1 \sim \chi^2(n_1), Y_2 \sim \chi^2(n_2)$ 且 $Y_1,Y_2$ 相互独立，则 $Y_1+Y_2 \sim \chi^2(n_1+n_2)$

- 统计性：对于 $Y \sim \chi^2(n)$，有 $EY = n, DY = 2n$

??? note "推导"
    EY 的推导利用：$EX^2 = DX - (EX)^2$
    ![EY 的推导](https://cdn.dwj601.cn/images/202405211524059.png)
    DY 的推导利用：方差计算公式、随机变量函数的数学期望进行计算
    ![DY 的推导](https://cdn.dwj601.cn/images/202405211524574.png)

$t$ 分布：

密度函数图像：

![密度函数图像](https://cdn.dwj601.cn/images/202405171014091.webp)

定义：

- 若随机变量 $X \sim N(0, 1),Y \sim \chi^2 (n)$ 且 $X,Y$ 相互独立
- 则称随机变量 $T = \displaystyle \frac{X}{\sqrt{Y/n}}$ 为服从自由度为 $n$ 的 $t$ 分布，记作 $T \sim t(n)$

性质：

- 密度函数是偶函数，具备对称性

$F$ 分布：

密度函数图像：

![密度函数图像](https://cdn.dwj601.cn/images/202405171015933.webp)

定义：

- 若随机变量 $X \sim \chi^2(m), Y \sim \chi^2(n)$ 且相互独立
- 则称随机变量 $G=\displaystyle \frac{X/m}{Y/n}$ 服从自由度为 $(m,n)$ 的 $F$ 分布，记作 $G \sim F(m, n)$

性质：

- 倒数自由度转换：$\displaystyle \frac{1}{G} \sim F(n, m)$
- [三变性质](https://zhuanlan.zhihu.com/p/382940609)：$\displaystyle F_{1-\alpha}(m, n) = \left [F_\alpha (n, m)\right]^{-1}$

#### 6.4.2 正态总体抽样分布基本定理

设 $X_1,X_2,\cdots ,X_n$ 是来自正态总体 $N(\mu, \sigma^2)$ 的简单随机样本，$\overline{X},S^2$ 分别是样本均值和修正样本方差。则有：

定理：

- $\displaystyle \overline{X} \sim N(\mu, \frac{\sigma^2}{n})$
- $\displaystyle \frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$
- $\overline{X}$ 和 $S^2$ 相互独立

推论：

- $\displaystyle \frac{\sqrt{n}(\overline{X} - \mu)}{S} \sim t(n-1)$

## 7 参数估计

有些时候我们知道数据的分布类型，但是不清楚表达式中的某些参数，这就需要我们利用「已有的样本」对分布表达式中的参数进行估计。本章我们将从点估计、估计评价、区间估计三部分出发进行介绍。

### 7.1 点估计

所谓点估计策略，就是直接给出参数的一个估计值。本目我们介绍点估计策略中的两个方法：矩估计法、极大似然估计法。

#### 7.1.1 矩估计法

其实就一句话：我们用样本的原点矩 $A_k$ 来代替总体 $E(X^k)$，$k$ 个未知参数就需要用到 $k$ 个原点矩：

$$
E(X^k) = A_k =  \frac{1}{n}\sum_{i=1}^nX_i^k
$$

#### 7.1.2 极大似然估计法

基本原理是：在当前样本数据的局面下，我们希望**找到合适的参数使得当前的样本分布情况发生的概率最大**。由于各样本相互独立，因此我们可以用连乘的概率公式来计算当前局面的概率值：

$$
L(\theta;x_1,x_2,\cdots,x_n)
$$

上述 $L(\theta;x_1,x_2,\cdots,x_n)$ 即似然函数，目标就是选择适当的参数 $\theta$ 来最大化似然函数。无论是离散性还是连续型，都可以采用下面的方式来计算极大似然估计：

1. 写出似然函数 $L(\theta)$
2. 将上述似然函数取对数
3. 求对数似然函数关于所有未知参数的偏导并计算极值点
4. 解出参数关于样本统计量的表达式

离散型随机变量的似然函数表达式

$$
L(\theta) = \prod_{i=1}^n p(x_i;\theta) = \prod_{i=1}^n P(X_i = x_i)
$$

连续型随机变量的似然函数表达式

$$
L(\theta) = \prod_{i=1}^n p(x_i;\theta)
$$

可以看出极大似然估计本质上就是一个多元函数求极值的问题。特别地，当我们没法得到参数关于样本统计量的表达式 $L(\theta)$ 时，可以直接从定义域、原函数恒增或恒减等角度出发求解这个多元函数的极值。

### 7.2 估计量的评价标准

如何衡量不同的点估计方法好坏？我们引入三种点估计量的评价指标：无偏性、有效性、一致性。其中一致性一笔带过，不做详细讨论。补充一点，参数的估计量 $\theta$ 是关于样本的统计量，因此可以对其进行求期望、方差等操作。

#### 7.2.1 无偏性

顾名思义，就是希望估计出来的参数量尽可能不偏离真实值。我们定义满足下式的估计量 $\hat \theta$ 为真实参数的无偏估计：

$$
E\hat \theta =\theta
$$

#### 7.2.2 有效性

有效性是基于比较的定义方法。对于两个无偏估计 $\hat\theta_1,\hat\theta_2$，谁的方差越小谁就越有效。即若 $D(\hat\theta_1),D(\hat\theta_2)$ 满足下式，则称 $\hat\theta_1$ 更有效

$$
D(\hat\theta_1) < D(\hat\theta_2)
$$

#### 7.2.3 一致性

即当样本容量 n 趋近于无穷时，参数的估计值也能趋近于真实值，则称该估计量 $\hat\theta$ 为 $\theta$ 的一致估计量

### 7.3 区间估计

由于点估计只能进行比较，无法对单一估计进行性能度量。因此引入「主元法」的概念与「区间估计」策略

#### 7.3.1 基本概念

可靠程度：参数估计区间越长，可靠程度越高

精确程度：参数估计区间越短，可靠程度越高

#### 7.3.2 区间估计常用方法之主元法

主元法的核心逻辑就一个：在已知数据总体分布的情况下，构造一个关于样本 $X$ 和待估参数 $\theta$ 的函数 $Z(X,\theta)$，然后利用置信度和总体分布函数，通过查表得到 $Z(X,\theta)$ 的取值范围，最后通过移项变形得到待估参数的区间，也就是估计区间。

#### 7.3.3 正态总体的区间估计

我们只需要掌握「一个总体服从正态分布」的情况。这种情况下的区间估计分为三种，其中估计均值 $\mu$ 有 2 种，估计方差 $\sigma^2$ 有 1 种。估计的逻辑我总结为了以下三步：

1. 构造主元 $Z(X,\theta)$
2. 利用置信度 $1-\alpha$ 计算主元 $Z$ 的取值范围
3. 对主元 $Z$ 的取值范围移项得到参数 $\theta$ 的取值范围

为了提升区间估计的可信度，我们希望上述第 2 步计算出来的关于主元的取值范围尽可能准确。我们不加证明的给出以下结论：取主元的取值范围为 **主元服从的分布的上下 $\frac{\alpha}{2}$ 分位数之间**。

**(一) 求 $\mu$ 的置信区间，$\sigma^2$ 已知**

构造主元 $Z(X,\theta)$：

$$
Z = \frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \sim N(0,1)
$$

利用置信度 $1-\alpha$ 计算主元 $Z$ 的取值范围：

$$
\begin{aligned}
P(|Z| \le \lambda) &= 1-\alpha \\
&\downarrow\\
Z \in [-\lambda,\lambda] &= [-u_{\frac{\alpha}{2}},u_\frac{\alpha}{2}]
\end{aligned}
$$

对主元 $Z$ 的取值范围移项得到参数 $\theta$ 的取值范围：

$$
\overline{X} - \frac{\sigma}{\sqrt{n}} u_\frac{\alpha}{2} \le \mu \le \overline{X} + \frac{\sigma}{\sqrt{n}} u_\frac{\alpha}{2}
$$

**(二) 求 $\mu$ 的置信区间，$\sigma^2$ 未知**

构造主元 $Z(X,\theta)$：

$$
Z = \frac{\overline{X} - \mu}{S / \sqrt{n}} \sim t(n-1)
$$

利用置信度 $1-\alpha$ 计算主元 $Z$ 的取值范围：

$$
\begin{aligned}
P(|Z| \le \lambda) &= 1-\alpha \\
&\downarrow\\
Z \in [-\lambda,\lambda] &= [-t_{\frac{\alpha}{2}}(n-1),t_\frac{\alpha}{2}(n-1)]
\end{aligned}
$$

对主元 $Z$ 的取值范围移项得到参数 $\theta$ 的取值范围：

$$
\overline{X} - \frac{S}{\sqrt{n}} t_\frac{\alpha}{2}(n-1) \le \mu \le \overline{X} + \frac{S}{\sqrt{n}} t_\frac{\alpha}{2}(n-1)
$$

**(三) 求 $\sigma^2$ 的置信区间，构造的主元与总体均值无关，因此不需要考虑 $\mu$ 的情况：**

构造主元 $Z(X,\theta)$：

$$
Z = \frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)
$$

利用置信度 $1-\alpha$ 计算主元 $Z$ 的取值范围：

$$
\begin{aligned}
P(\lambda_1 \le Z \le \lambda_2) &= 1-\alpha \\
&\downarrow\\
Z \in [\lambda_1,\lambda_2] &= [\chi^2_{1-\frac{\alpha}{2}}(n-1),\chi^2_\frac{\alpha}{2}(n-1)]
\end{aligned}
$$

对主元 $Z$ 的取值范围移项得到参数 $\theta$ 的取值范围：

$$
\frac{(n-1)S^2}{\chi^2_\frac{\alpha}{2}(n-1)} \le \sigma^2 \le \frac{(n-1)S^2}{\chi^2_{1-\frac{\alpha}{2}}(n-1)}
$$

## 8 假设检验

第 7 章的参数估计是在总体分布已知且未知分布表达式中某些参数的情况下，基于「抽取的少量样本」进行的参数估计。

现在的局面同样，我们已知总体分布和不完整的分布表达式参数。现在需要我们利用抽取的少量样本判断样本所在向量空间是否符合某种性质。本章的「假设检验」策略就是为了解决上述情况而诞生的。我们主要讨论单个正态总体的情况并针对均值和方差两个参数进行假设和检验：

- 假设均值满足某种趋势，利用已知数据判断假设是否成立
- 假设方差满足某种趋势，利用已知数据判断假设是否成立

### 8.1 假设检验的基本概念

基本思想：首先做出假设并构造一个关于样本观察值和已知参数的检验统计量，接着计算假设发生的情况下小概率事件发生时该检验统计量的取值范围（拒绝域），最终代入已知样本数据判断计算结果是否在拒绝域内。如果在，则说明在当前假设的情况下小概率事件发生了，对应的假设为假；反之说明假设为真。

为了量化「小概率事件发生」这个指标，我们引入显著性水平 $\alpha$ 这一概念。该参数为一个很小的正数，定义为「小概率事件发生」的概率上界。

基于数据的实验导致我们无法避免错误，因此我们定义以下两类错误：

- 第一类错误：弃真错误。即假设正确，但由于数据采样不合理导致拒绝了真实的假设
- 第二类错误：存伪错误。即假设错误，同样因为数据的不合理导致接受了错误的假设

### 8.2 单个正态总体均值的假设检验

设 $X_1,X_2,\cdots ,X_n$ 是来自正态总体 $N(\mu, \sigma^2)$ 的简单随机样本。后续进行假设判定计算统计量 $Z$ 的真实值时，若总体均值 $\mu$ 已知就直接代入，若未知题目也一定会给一个阈值，代这个阈值即可。

当总体方差 $\sigma^2$ 已知时，我们构造样本统计量 $Z$ 为正态分布：

$$
Z = \frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \sim N(0,1)
$$

- 检验是否则求解双侧 $\alpha$ 分位数
- 检验单边则求解单侧 $\alpha$ 分位数

当总体方差 $\sigma^2$ 未知时，我们构造样本统计量 $Z$ 为 $t$ 分布：

$$
Z = \frac{\overline{X} - \mu}{S / \sqrt{n}} \sim t(n-1)
$$

???+ warning
    之所以这样构造是因为当总体 $\sigma$ 未知时，上一个方法构造的主元已经不再是统计量，我们需要找到能够代替未知参数 $\sigma$ 的变量，这里就采用其无偏估计「修正样本方差 $S^2$」来代替 $\sigma^2$。也是说直接拿样本的修正方差来代替总体的方差了。

- 检验是否则求解双侧 $\alpha$ 分位数
- 检验单边则求解单侧 $\alpha$ 分位数

### 8.3 单个正态总体方差的假设检验

设 $X_1,X_2,\cdots ,X_n$ 是来自正态总体 $N(\mu, \sigma^2)$ 的简单随机样本。后续进行假设判定计算统计量 $Z$ 的真实值时，若总体方差 $\sigma^2$ 已知就直接代入，若未知题目也一定会给一个阈值，代这个阈值即可。

我们直接构造样本统计量 $Z$ 为 $\chi^2$ 分布：

$$
Z = \frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)
$$

- 检验是否则求解双侧 $\alpha$ 分位数
- 检验单边则求解单侧 $\alpha$ 分位数
