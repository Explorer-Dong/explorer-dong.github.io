---
title: 机器学习导读
status: new
---

本文记录「机器学习」相关内容，初稿完成于大二下学期。由于本人比较喜欢自顶向下式地动手学习领域知识，而现在的教材大多都是扁平化的平铺知识点，因此本文的组织结构就按照代码逻辑中的 **数据**、**模型**、**损失** 三个方面顺序展开。

考虑到笔记内容的重要性与时效性，本文会不断完善。部分参考内容 [^西瓜书] [^南瓜书] [^nndl] 见本文文末。

[^西瓜书]: [周志华，机器学习与模式识别，清华大学出版社，2016.](https://github.com/jingyuexing/Ebook/blob/master/Machine_Learning/机器学习_周志华.pdf)
[^南瓜书]: [机器学习公式详解，人民邮电出版社，2023.](https://github.com/datawhalechina/pumpkin-book)
[^nndl]: [邱锡鹏，神经网络与深度学习，机械工业出版社，2020.](https://nndl.github.io/)

一些衍生内容：

- 课程设计。我与团队成员一起，使用 XGBoost 和 MLP 实现了高糖预测 [^课设]；
- 深度学习。详见第五学期的 [神经网络与深度学习](../deep-learning/index.md) 课程笔记；
- 强化学习。该领域主要通过建立「策略概率模型」来学习数据的动态变化，从而让智能体做出最佳决策。笔记内容待定。

[^课设]: [机器学习课程设计 | Lu, H., Dong, W., et al. - (github.com)](https://github.com/Mr-LUHAOYU/MachineLearningClassDesign)

## 机器学习的任务

在我看来，机器学习是一种「通过学习数据规律，实现诸如 **预测**、**生成**、**决策** 等实际任务的」研究范式。下表罗列了三类机器学习任务的实际建模策略：

| 概率建模类型 |        核心问题        |           实际应用           |
| :----------: | :--------------------: | :--------------------------: |
| 条件概率建模 | 给定输入，输出是什么？ |    分类、回归、翻译、检测    |
| 联合概率建模 |     数据如何生成？     |     生成、修复、异常检测     |
| 策略概率建模 | 如何行动以最大化收益？ | 强化学习、资源优化、主动学习 |

/// tc | <
机器学习的建模策略
///

由于机器学习领域十分宏大，衍生出的很多子分支也极具研究价值，因此本文仅仅针对传统的机器学习本身展开。深度学习、强化学习等子领域不在本文的讨论范围内。

## 机器学习的术语

- 计算学习理论：概率近似正确 (Probably Approximately Correct, PAC) 理论。即以很高的概率得到很好的模型 $P(f(x)- y \le \epsilon) \ge 1 - \delta$；
- P 问题：在多项式时间内计算出答案的解；
- NP 问题：在多项式时间内检验解的正确性；
- 学习任务：监督学习、无监督学习、半监督学习、强化学习；
- 泛化能力：应对未见样本的平均拟合能力；
- 假设空间：所有可能的样本组合构成的集合空间；
- 独立同分布假设：历史和未来的数据来自相同的分布；
- No Free Launch 理论：没有绝对好的算法，只有适合的算法。好的算法来自于对数据的好假设、好偏执。在实际应用时，我们需要大胆假设，小心求证。

## 机器学习的步骤

1. 获取数据。获取数据后我们要对数据进行预处理，例如：数据清洗、特征筛选等；
2. 确定模型。有了数据我们需要根据数据特点和任务场景确定好待学习的模型，例如：线性模型、非线性模型等；
3. 学习准则。我们还需要根据学习任务确定学习准则，也就是需要确定目标函数/损失函数，例如：交叉熵损失、平均方差等；
4. 优化方法。有了损失函数以后我们就可以利用最优化理论中的各种优化方法来迭代求得最佳得模型参数，例如：梯度下降法、动量法等。
