---
title: 机器学习导读
---

> 科学发展范式：实验科学 $\to$ 理论科学 $\to$ 计算科学 $\to$ 数据科学。

本文记录机器学习 [^西瓜书] [^南瓜书] [^nndl] 相关内容。

[^西瓜书]: [周志华，机器学习与模式识别，清华大学出版社，2016.](https://github.com/jingyuexing/Ebook/blob/master/Machine_Learning/机器学习_周志华.pdf)
[^南瓜书]: [机器学习公式详解，人民邮电出版社，2023.](https://github.com/datawhalechina/pumpkin-book)
[^nndl]: [邱锡鹏，神经网络与深度学习，机械工业出版社，2020.](https://nndl.github.io/)

机器学习是一种「通过学习数据规律，实现诸如 **预测**、**生成**、**决策** 等实际任务的」研究范式。下表罗列了三类机器学习任务的实际建模策略：

| 概率建模类型 |        核心问题        |       实际应用       |
| :----------: | :--------------------: | :------------------: |
| 条件概率建模 | 给定输入，输出是什么？ |      分类、回归      |
| 联合概率建模 |     数据如何生成？     | 生成、修复、异常检测 |
| 策略概率建模 | 如何行动以最大化收益？ |  强化学习、资源优化  |

由于机器学习领域十分宏大，衍生出的子分支也极具研究价值，考虑到文章定位以及篇幅问题，本文仅仅针对传统机器学习展开。[深度学习](../deep-learning/index.md)、强化学习等子领域不在本文的讨论范围内。

机器学习的常见术语：

- 计算学习理论：概率近似正确 (Probably Approximately Correct, PAC) 理论。即以很高的概率得到很好的模型 $P(f(x)- y \le \epsilon) \ge 1 - \delta$；
- P 问题：在多项式时间内计算出答案的解；
- NP 问题：在多项式时间内检验解的正确性；
- 学习任务：监督学习、无监督学习、半监督学习、强化学习；
- 泛化能力：应对未见样本的平均拟合能力；
- 假设空间：所有可能的样本组合构成的集合空间；
- 独立同分布假设：历史和未来的数据来自相同的分布；
- No Free Launch 理论：没有绝对好的算法，只有最适合的算法。好的算法来自于对数据的好假设、好偏执。在实际应用时，我们需要大胆假设，小心求证。

机器学习的一般范式：

1. 数据处理。数据决定上限，我们需要仔细分析数据特点并进行细致的预处理工作，例如：数据分析、数据清洗、特征工程等；
2. 模型构建。数据处理完后，我们需要根据数据特点和任务场景确定机器学习模型，例如：线性模型、非线性模型等，而每一个模型都必须有一个待优化的目标（一般称为学习准则/目标函数/损失函数），例如：经验风险最小化、结构风险最小化、最大似然估计、最大后验估计 [^nndl]；
3. 参数学习。确定好待优化的目标后，我们就可以利用 [最优化理论](../../math/optimization-method/index.md) 中的各种数值优化方法来迭代式地求解/学习出模型的最佳参数，例如：梯度下降法、牛顿法、拟牛顿法等；
4. 超参调优。模型有「可训练」参数和「不可训练」参数，步 $3$ 只能学习前者，后者需要手动调整。在将数据集划分为训练集、验证集和测试集的情况下，一般使用训练集学习可训练的参数，使用验证集来度量不同超参数下的模型性能，最终选择验证集上表现最好的模型在最终的测试集上进行测试。常见的超参调优方法 [^hyper-param] 有：网格搜索、随机搜索、贝叶斯优化。

[^hyper-param]: [四种主流超参数调优技术 | McGL - (zhuanlan.zhihu.com)](https://zhuanlan.zhihu.com/p/234509605)
